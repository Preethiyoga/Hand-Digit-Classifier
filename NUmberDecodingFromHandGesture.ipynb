{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e43210-85df-4ab4-a6ea-83612bf4e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os ## to access directories\n",
    "from PIL import Image ## to read Images\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b0c469-7e68-4bb7-a747-78733f1b3ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = \"./SignLanguageDigitsDatase/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72d169-397f-481a-bd90-4ce9c675643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold = np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d29dc89-7eab-4955-9001-36269463d08f",
   "metadata": {},
   "source": [
    "Backpropagation in CNN layer: https://www.youtube.com/watch?app=desktop&v=z9hJzduHToc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faef7fd-3f42-44ef-9058-dc1dafa0a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "commonepoch=np.empty((0,), dtype=int)\n",
    "commonloss=np.empty((0,), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecee797-4fad-457c-8c4c-e1bac2e817ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDS(name):\n",
    "    folder = \"SignLanguageDigitsDatase/\"\n",
    "    lblist = []\n",
    "    imglist = []\n",
    "    for i in range(0,10):\n",
    "        lb = np.zeros(10)\n",
    "        lb[i]=1\n",
    "        for image in os.listdir(folder+name+\"/A\"+str(i)):\n",
    "            img = Image.open(folder+name+\"/A\"+str(i)+\"/\"+image).convert('RGB').resize((100,100))\n",
    "            np_img= np.array(img)\n",
    "            print(np_img.shape)\n",
    "            np_img = np_img/255.0 ## Normalizing the images to be between 0 and 255\n",
    "            lblist.append(lb)\n",
    "            imglist.append(np_img)\n",
    "    return np.array(imglist), np.array(lblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c599589-545d-494a-ad78-76763463ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y=createDS(\"train\")\n",
    "indices = np.arange(len(train_x))\n",
    "np.random.shuffle(indices)\n",
    "#print(indices)\n",
    "train_x = train_x[indices]\n",
    "train_y = train_y[indices]\n",
    "#print(train_y)\n",
    "test_x, test_y=createDS(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c536325-1951-4200-baf8-5d9ea8e1df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_x, valid_y=createDS(\"valid\")\n",
    "\n",
    "indices = np.arange(len(valid_x))\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "valid_x = valid_x[indices]\n",
    "valid_y = valid_y[indices]\n",
    "print(valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d052b3-29fa-4f57-acf2-246c8085459e",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247ebcc-6c85-4563-b6c8-034dec09c03c",
   "metadata": {},
   "source": [
    "### CNN - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085e8d9-a3b8-4625-9e5b-1b2105671fae",
   "metadata": {},
   "source": [
    "#### Buliding First Layer -- Input layer\n",
    "\n",
    "Input layer --> where we pass in the image (64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46817b4e-b0f5-4a14-b1e7-45626ba2a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_layer(img1dSet):\n",
    "    img3dset = np.zeros_like(img1dSet)\n",
    "    for i in range(len(img1dSet)):\n",
    "        img3dset[i]= img1dSet[i].reshape((100,100,3))\n",
    "    return img3dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e0fc5-8838-406b-9251-640e160a811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = input_layer(train_x)\n",
    "test_x = input_layer(test_x)\n",
    "valid_x = input_layer(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf927d24-34e2-4570-beb2-6df9230fe40c",
   "metadata": {},
   "source": [
    "#### Buliding Second layer -- Convolution layer\n",
    "\n",
    "Convolution layer -- applies filter to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5d042-b6cd-422c-9ef8-a7f1a21dac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The filter learns and extracts features from the image. can be of 3*3 or 5*5 size\n",
    "# The stride determines how much the filter moves at a time, which affects the resolution and size of the output.\n",
    "# The padding ensures that the spatial size of the image can be maintained or controlled, preventing the image from shrinking too much as we move deeper into the network.\n",
    "\n",
    "\n",
    "## striding --> resolution of the image --> 1\n",
    "## padding --> size of the output image\n",
    "\n",
    "# output size= (Inp size+2*padding- filter size)/stride +1\n",
    "\n",
    "# for 64*64 size image the padding\n",
    "\n",
    "# 64 = (64+2*pad - 3)/1 +1\n",
    "# 66 = 64 + 2*pad\n",
    "# 2 = 2* pad\n",
    "# pad = 1\n",
    "\n",
    "\n",
    "## Going to define the convolutional layer with 'n' filter each as a class\n",
    "\n",
    "\n",
    "class ConvLayer:\n",
    "    def __init__(self, n_filters, filter_size, inp_depth, stride = 1, padding = 1):\n",
    "        self.fcnt = n_filters\n",
    "        self.fsize = filter_size\n",
    "        self.fdepth = inp_depth\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.filters = np.random.randn(n_filters, filter_size, filter_size, inp_depth)*0.1\n",
    "    ##created n no. of filters randomly which will form a convolution layer\n",
    "\n",
    "    \n",
    "    def conv(self, img3d): \n",
    "        self.input = img3d\n",
    "        # print(\"original image\")\n",
    "        # plt.imshow(img3d) #for grayscale\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "        h,w,d = img3d.shape\n",
    "        # we will iterate the convolution function over our image the \"output_image size\" no. of times. \n",
    "        # the size of output depends on a folrmula\n",
    "        # output size= (Inp size+2*padding- filter size)/stride +1\n",
    "\n",
    "        out_h = (h+ 2*self.padding - self.fsize)//self.stride +1\n",
    "        out_w = (w+ 2*self.padding - self.fsize)//self.stride +1\n",
    "        ##Gist of what will this convolution function do\\\n",
    "        ## --> Slides the filter across the input image\n",
    "        ## --> During each slides.. accumulates the dot product( single value) of filter and inpImg and stores in Output image\n",
    "        img3d = np.pad(img3d,((self.padding, self.padding),(self.padding,self.padding),(0,0)),mode = 'constant', constant_values=0)\n",
    "        out_img = np.zeros((h,w,self.fcnt)) ## in tradition it is h,w,fcnt.. preferred for later std library algorithms\n",
    "        ## this output_img will be an 1d output of all filters' featuremaps\n",
    "        for k in range(self.fcnt): ## for each filter\n",
    "            f= self.filters[k]\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    ## For each iteration we must identify starting and ending indices in our input Image\n",
    "                    start_h = i*self.stride\n",
    "                    end_h = i+self.fsize\n",
    "                    start_w = j*self.stride\n",
    "                    end_w = j+ self.fsize\n",
    "    \n",
    "                    region = img3d[start_h:end_h, start_w:end_w,:]\n",
    "                    out_img[i,j,k] = np.sum(region * f)\n",
    "        \n",
    "        ## this output_img will be an 1d output of all filters' featuremaps\n",
    "        return out_img ## a 3d image [no. of filter,h,w] ## fcnt is no more--> np.sum(would have summed all indices value and output one value per i,j for a filter\n",
    "    def getfilters(self):\n",
    "        print(\"filters:\", self.filters)\n",
    "        #print(\"Bias:\", self.bias)\n",
    "    def activate(self, img3d):\n",
    "        ## Apply the convolution then apply ReLU Activation function\n",
    "        self.input=img3d ## stored for backward propagation\n",
    "        imgconv = self.conv(self.input)\n",
    "        relu_img = np.maximum(0,imgconv)\n",
    "        self.relu = relu_img\n",
    "        return relu_img  \n",
    "\n",
    "    ## for backward propagation the filter needs to be updated again\n",
    "    ## Where to apply backward propagation -- key is to optimize all the randomly initiated things \n",
    "    ## here filters\n",
    "    def backProp(self,dz, learning_rate = 0.01):\n",
    "        ## dz should also be a 3d image of size [no. of filter, h,w]\n",
    "        h,w,fcnt = dz.shape\n",
    "        dw= np.zeros_like(self.filters) ## creating gradient for filter matrix\n",
    "        for k in range(self.fcnt):\n",
    "            f = self.filters[k]\n",
    "            for i in range(h-self.fsize):\n",
    "                for j in range (w-self.fsize):\n",
    "                    region = self.input[i:i+self.fsize, j:j+self.fsize, :]\n",
    "                    #print(region.shape, dz[i,j,k].shape)\n",
    "                    dw[k] += region*dz[i,j,k]\n",
    "        ## backward\n",
    "        self.filters -= learning_rate* dw\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769c82d-ea2e-4e17-844c-16e9888e7087",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f522b-7710-453f-bb2f-c49ba3f1625b",
   "metadata": {},
   "source": [
    "#### Max pooling â†’ Focuses on strongest features (e.g., strong edges or patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9869095-fa18-4cb4-a14f-21e738fc1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer:\n",
    "    def __init__(self, pool_size=2, stride = 2):\n",
    "        self.pool_size= pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def pool(self,input):\n",
    "        ## now we have image input as (64, 64, nfilters)\n",
    "        ## ie nfilters number of feature maps\n",
    "        ## Now we need to reduce the 64 * 64 image to 32 * 32\n",
    "        ## Max pooling that is taking maximum out of each 2*2 matrices --> can retain the sharp features of the image\n",
    "        ## Uses of POoling --> Reduce size and avoids overfitting for the model\n",
    "        self.size= input.shape\n",
    "        h,w,fcnt = input.shape\n",
    "\n",
    "        out_h = (h - self.pool_size) // self.stride + 1\n",
    "        out_w = (w - self.pool_size) // self.stride +1\n",
    "        self.indmax = np.zeros((out_h,out_w,fcnt,2) , dtype= int)\n",
    "\n",
    "        pooled_output = np.zeros((out_h,out_w, fcnt))\n",
    "        #print (out_h, out_w)\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                for k in range(fcnt):\n",
    "                    start_h = i*self.stride\n",
    "                    end_h = start_h + self.pool_size\n",
    "                    start_w = j*self.stride\n",
    "                    end_w = start_w + self.pool_size\n",
    "                    region = input[start_h:end_h, start_w:end_w, k]\n",
    "                    pooled_output[i,j,k] = np.max(region)\n",
    "                    max_idx = np.unravel_index(np.argmax(region), region.shape) ## the argmax output will be the index of maximum in the 1d array\n",
    "                    ## eg: argmax output --> 0,1,2,3, ( 1d index\n",
    "                    ## Unravelled --> (0,0), (0,1), (1,0), (1,1)\n",
    "                    ## Now we wanna it to be positioned inside the region;\n",
    "                    self.indmax[i,j,k]= (start_h + max_idx[0], start_w+max_idx[1])  \n",
    "                    ## we will pass flattened output to our fully connected layer\n",
    "        #plotting each filters output\n",
    "        # print (\"Output of MaxPool:\")\n",
    "        # for i in range(fcnt):\n",
    "        #     array = pooled_output[:,:,i]\n",
    "        #     plt.imshow(array, cmap = 'gray') #for grayscale\n",
    "        #     plt.axis('off')\n",
    "        #     plt.show()\n",
    "            \n",
    "        pooled_output = pooled_output.reshape(-1)\n",
    "        pooled_output = pooled_output.reshape(pooled_output.shape[0],1)\n",
    "        \n",
    "        #print (pooled_output.shape)\n",
    "        return pooled_output\n",
    "    ### Back Propagation in Max Pooling layer:\n",
    "    ##  we need to revert back all the changes the \"Max pooling layer\" did to the image\n",
    "    ## 1. reshape to 1 d array\n",
    "    ## 2. refuce image size from 64 * 64 to 32 * 32\n",
    "    ## Now the Loss will be affected only by the max value of each 2*2 matrix\n",
    "    ## therefore, gradient is the whole output of only the max value. so the gradient should reside in the cell of max value.\n",
    "    ## for that we need to store the index of max value in a matrix \n",
    "    def backProp(self,gradient):\n",
    "        h,w,fcnt = self.size\n",
    "        #print ( gradient.shape)\n",
    "        gradient = gradient.reshape((h//self.pool_size, w//self.pool_size, fcnt))\n",
    "        #print ( gradient.shape)\n",
    "        self.dinput = np.zeros(self.size)\n",
    "        for i in range(h//self.pool_size):\n",
    "            for j in range(w//self.pool_size):\n",
    "                for k in range(fcnt):\n",
    "                    pos_max = self.indmax[i,j,k]\n",
    "                    self.dinput[pos_max[0], pos_max[1], k]= gradient[i,j,k]\n",
    "\n",
    "        #print(self.dinput.shape)\n",
    "        return self.dinput ## backwarded\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4da4d-4af0-43e2-aa98-4969c8b95dcb",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5418d08c-07ca-4b80-9766-33dc53124328",
   "metadata": {},
   "source": [
    "## Output Layer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282de838-8a0c-4be7-9959-d660715c199d",
   "metadata": {},
   "source": [
    "#### We will define weights for the link as small random numbers and ML algorithm should tweak the weight according to the error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbe6f3-21b0-4a71-b655-84db3c566acd",
   "metadata": {},
   "source": [
    "#### Responsible to output the class to which the input image belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4f52c-f567-49ec-b8fb-049449685eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fullyconnected:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size,output_size) * 0.01\n",
    "        self.biases = np.zeros ((1, output_size))\n",
    "    def forward(self, img):\n",
    "        self.input = img ## useful for BackPropagation-- img -- pooled and flattened output initially then previous forward output \n",
    "        output = np.dot(self.input.T,self.weights)+self.biases \n",
    "        exp = np.exp(output - np.max(output))\n",
    "        #self.bploss = self.softmax - labels ## loss for backpropagation\n",
    "        self.softmax = exp / (np.sum(exp)+1e-15) ## softmaxed output --> output turned to probabilities\n",
    "        #print(\"softmax:\",self.softmax, \"exp:\" ,exp)\n",
    "        #print(self.softmax.shape)\n",
    "        #print(self.input.shape)\n",
    "        return self.softmax\n",
    "    #### Cross - Entropy loss : when the task is multi class classification cross - entropy loss can work better with the one-hot encoded labels\n",
    "    def crossEntropyCalculator(self, labels):\n",
    "        pred = np.argmax(self.softmax)\n",
    "        actual = np.argmax(labels)\n",
    "        print(\"Actual: \" , actual, \"Prediction: \", pred)\n",
    "        epsilon = 1e-15\n",
    "        clipped_preds = np.clip(self.softmax, epsilon, 1-epsilon)\n",
    "        loss = np.sum(-labels*np.log(clipped_preds))/ labels.shape[0]\n",
    "        return loss   ## for tracting the predictability variations of the model \n",
    "    ## BackPropagation\n",
    "    ### Calculating Gradient and Updating weights using optimizer\n",
    "    def backProp(self, labels, learning_rate = 0.01):\n",
    "        dz = self.softmax - labels  ## derivation of softmax - cross entropy-- average loss calcultion for gradients\n",
    "        #print(labels)\n",
    "        self. dw = np.dot(self.input,dz)\n",
    "        self. db = np.sum(dz,axis=0)\n",
    "        self.dw = np.clip(self.dw, -1.0,1.0)\n",
    "        self.db = np.clip(self.db, -1.0, 1.0)\n",
    "        dinput = np.dot(self.weights,dz.T)\n",
    "        self.weights -= learning_rate*self.dw\n",
    "        self.biases-= learning_rate*self.db\n",
    "        return dinput\n",
    "    def getwb(self):\n",
    "        print(\"weights:\",self.weights)\n",
    "        print(\"bias:\", self.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d17bd4-5303-4d2f-9823-5da8c0e81fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c2a4d-7973-4f52-ae43-80c3f90370f0",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2d591-ecc5-4ff6-81c8-55d61c50a9e2",
   "metadata": {},
   "source": [
    "### Logic behind the training loop\n",
    "--> filter\n",
    "--> for each filtered output -- Max pooling \n",
    "--> forward with fully connected layer\n",
    "--> calculate entropy\n",
    "--> back propagate \n",
    "--> print loss for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e8cd3-afb0-4c02-a812-f0be1a3e13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, Y_train, epochs, learning_rate):\n",
    "    lossar = np.zeros((epochs))\n",
    "    entLoss = np.zeros((len(X_train)))\n",
    "    for e in range(epochs):\n",
    "        total_loss = 0\n",
    "        indices = np.arange(len(X_train))\n",
    "        np.random.shuffle(indices)\n",
    "        print(indices)\n",
    "        X_train = X_train[indices]\n",
    "        Y_train = Y_train[indices]\n",
    "        print(train_y)\n",
    "        ## for each input image\n",
    "        for  i in range(len(X_train)):\n",
    "            x = X_train[i]\n",
    "            y = Y_train[i]\n",
    "            ##print(y)\n",
    "            ## -- filter or convolution \n",
    "            filtered = model[0].activate(x)\n",
    "            ## -- Maxpooling\n",
    "            pooled = model[1].pool(filtered)\n",
    "            ## fully connected\n",
    "            final = model[-1].forward(pooled)\n",
    "            ## Cross Entropy \n",
    "            loss = model[-1].crossEntropyCalculator(y)\n",
    "            entLoss [i] = loss ## to plot loss movement in a parabola\n",
    "            ## Back Propagation on each layer\n",
    "            dfinal = model[-1].backProp(y, learning_rate)\n",
    "            ## BackProp in MaxPooling\n",
    "            dpooled = model[1].backProp(dfinal)\n",
    "            ## BackProp in filter\n",
    "            dfiltered = model[0].backProp(dpooled, learning_rate)\n",
    "            ## Accumulated loss\n",
    "            total_loss += loss\n",
    "        ## For each epoch print accumulated Loss\n",
    "        avgLoss = total_loss\n",
    "        print (\"Epoch: \",e, \"; The Loss: \",avgLoss)\n",
    "        lossar[e] = avgLoss\n",
    "    return entLoss,lossar\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e3003-8e9c-4564-b856-b299f13a7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = [ConvLayer(8,3,3),\n",
    "# MaxPoolLayer(),\n",
    "# fullyconnected( 20000,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9f0be-252d-4266-b865-919638be881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1aefda-d2dc-4c80-857a-8ffabf110588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entLoss,epochloss = train(model,train_x, train_y, epochs, 0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab08b2a-45f4-446f-beba-02af515c3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting the loss - epoch \n",
    "commonepoch = list(range(len(commonepoch)+epochs))\n",
    "commonloss= np.append(commonloss, epochloss)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(commonepoch, commonloss, marker = 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6fe91-ebd9-4967-a0da-f4f5fd59c7c3",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ccadd5-5605-4f18-a3ef-c8b5170639d3",
   "metadata": {},
   "source": [
    "## Validation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b40b4-7afe-4a54-beb1-607c99a8ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, X_test, Y_test):\n",
    "    correct = 0 \n",
    "    tot_loss = 0\n",
    "    actVSpred = np.zeros((10,10))\n",
    "    crtPred = np.zeros((10))\n",
    "    for i in range(len(X_test)):\n",
    "        x = X_test[i]\n",
    "        y = Y_test[i]\n",
    "\n",
    "        ## -- filter or convolution \n",
    "        filtered = model[0].activate(x)\n",
    "        ## -- Maxpooling\n",
    "        pooled = model[1].pool(filtered)\n",
    "        ## fully connected\n",
    "        final = model[-1].forward(pooled)\n",
    "        ## Cross Entropy \n",
    "        loss = model[-1].crossEntropyCalculator(y)\n",
    "        ## Accumulated loss\n",
    "        tot_loss += loss\n",
    "        # Prediction = index of highest probability\n",
    "        pred = np.argmax(final)\n",
    "        actual = np.argmax(y)\n",
    "        #print(\"Actual: \" , actual, \"Prediction: \", pred)\n",
    "        if pred == actual:\n",
    "            crtPred[pred]+=1\n",
    "            correct+=1\n",
    "            print(\"OK\")\n",
    "        else:\n",
    "            actVSpred[actual, pred] +=1\n",
    "            print(\"Not OK\")\n",
    "    accuracy = correct / len(X_test)\n",
    "    avg_loss = tot_loss\n",
    "    print (\"No of total images:\", len(X_test))\n",
    "    print (\"No of valid prediction:\", correct)\n",
    "    print (\" Validation accuracy: \", accuracy)\n",
    "    print (\"Validation Loss: \", avg_loss)\n",
    "    print(\"Active VS PRediction 10/10 :\",actVSpred)\n",
    "    print(\"Correct Prediction :\", crtPred)\n",
    "    model[0].getfilters()\n",
    "    model[-1].getwb()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e959bff-7002-4e29-978d-a3ce915f4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f83e05-0759-4e45-be5d-f11cc55a1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73cadb-78ac-4195-ad15-dbc9eac8e327",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
